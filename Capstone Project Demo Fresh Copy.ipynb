{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## ================================================\n## PLEASE RUN THIS DEMO WITH PYTHON 2 AND SPARK 2.1\n## ================================================", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Credit Card Fraud Detection", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**Use Case:** The credit-card company has released an anonymized list of time-recorded European card transactions to detect fraudulent credit-card transactions for two days in September 2013. The data contains a highly imbalanced (small) percentage of transactions that are fraudulent. The goal is to train the computer to detect fraudulent transactions. To assess the performance of various machine/deep-learning algorithms, we carry out and evaluate two popular models that are often used to cope with imbalanced datasets. They are (1) *autoencoder neural networks*, (2) *support vector machines* and (3) *decision trees*. \n\n**Data Source:** Kaggle: https://www.kaggle.com/mlg-ulb/creditcardfraud\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Data inspection and ETL", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### The CSV file creditcard.csv is downloaded and stored in IBM Cloud Object Storage. Data from it are then extracted and converted to Spark dataframe with appropriate credentials.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import ibmos2spark\n\nconfiguration_name = 'os_3253229b087f481987a8b59b2f9ce876_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\n\nspark=SparkSession.builder.getOrCreate()\ndf_credit = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('creditcard.csv', 'ibmadvanceddatasciencecapstone-donotdelete-pr-iivs2mtioqigul'))\ndf_credit.take(5)"
        }, 
        {
            "source": "#### Data properties are checked.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "num_smp = df_credit.count() # Number of samples\nnum_feat = len(df_credit.columns) # Number of features\nprint(num_smp,num_feat)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_credit.printSchema()"
        }, 
        {
            "source": "#### Cast the entire dataframe to float format. Note that PCA is already performed on the original confidential dataset to form this current public dataset to protect the identities of the card users.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql.functions import col\n\ndf_credit=df_credit.select(*(col(c).cast(\"float\").alias(c) for c in df_credit.columns))\ndf_credit.printSchema()"
        }, 
        {
            "source": "#### We now upload the preprocessed dataframe to the persistent Spark storage format for later use.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql import SparkSession\n\nspark=SparkSession.builder.getOrCreate()\ndf_credit=df_credit.repartition(1)\ndf_credit.write.mode('overwrite').parquet(cos.url('credit.parquet','ibmadvanceddatasciencecapstone-donotdelete-pr-iivs2mtioqigul'))"
        }, 
        {
            "source": "### ===========================", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Load data from Object Storage", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import ibmos2spark\n\nfrom pyspark.sql import SparkSession\nspark=SparkSession.builder.getOrCreate()\n\nconfiguration_name = 'os_3253229b087f481987a8b59b2f9ce876_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\ndf_credit=spark.read.parquet(cos.url('credit.parquet','ibmadvanceddatasciencecapstone-donotdelete-pr-iivs2mtioqigul'))"
        }, 
        {
            "source": "### Load all packages", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport itertools\nimport json\n\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n                             roc_curve, recall_score, classification_report, f1_score,\n                             precision_recall_fscore_support)\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras import regularizers\n\nfrom pyspark.ml.classification import GBTClassifier, RandomForestClassifier\nfrom pyspark.ml.feature import VectorAssembler, Normalizer, StringIndexer\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml import Pipeline\nfrom pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nfrom pyspark.sql import DataFrame\n\nfrom functools import reduce"
        }, 
        {
            "source": "### Data visualization", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df=df_credit.toPandas()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_legal=df.loc[df['Class'] == 0]\ndf_fraud=df.loc[df['Class'] == 1]\n\ndf_legal=df_legal.values\ndf_fraud=df_fraud.values\n\ndf_legal.shape"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "size_l = len(df_legal)\nsize_f = len(df_fraud)\n\nplt.bar([0,1], [size_l,size_f], align='center', alpha=1)\nplt.xticks([0,1],['Legal','Fraudulent'])\nplt.ylabel('Frequency')\nplt.title('Credit-card transactions')\n \nplt.show()\n\nfig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nax.plot(df_legal[:,0], df_legal[:,29], '-', color='blue', animated = True, linewidth=1)\nax.plot(df_fraud[:,0], df_fraud[:,29], '-', color='red', animated = True, linewidth=1)\nplt.ylabel('Credit-card transaction amount')\nplt.xlabel('Time')\nplt.legend(['Legal','Fraudulent'],loc='best')\nplt.show()"
        }, 
        {
            "source": "#### As expected, the dataset is highly imbalanced with a very low percentage of fraudulent transactions. The above time series shows that, apart from the user characteristics V1 to V28, small transaction amounts are also signatures of fraudulent credit-card activities.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### (1) We first train the machine to detect fraudulent transactions with Autoencoders using Keras", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Preprocess the transactions data and group the legal transactions for training", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_prep=df.drop('Time',axis=1)                           # Remove the 'Time' column.\ndf_class=df_prep['Class']                                # Extract class labels store it.\nheader = list(df_prep)\ndf_prep=StandardScaler().fit(df_prep).transform(df_prep) # Perform standard feature scaling\ndf_prep=pd.DataFrame(data=df_prep,columns=header)        # Reinstate column headers\ndf_prep['Class']=df_class                                # Reinstate correct class labels\n\nX_train, X_rest = train_test_split(df_prep, test_size=0.4)  # Split data to 60% training, 20% validation and 20% test\nX_val, X_test = train_test_split(X_rest, test_size=0.5)\n\nX_train = X_train[X_train.Class == 0]\nX_train = X_train.drop('Class', axis=1)\ny_val = X_val['Class']\nX_val = X_val.drop('Class', axis=1)\ny_test = X_test['Class']\nX_test = X_test.drop('Class', axis=1)\n\nX_train = X_train.values\nX_val = X_val.values\nX_test = X_test.values\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)\nprint(X_test.shape)\nprint(y_test.shape)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_prep.head()"
        }, 
        {
            "source": "### Define the autoencoder model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "input_dim = X_train.shape[1]\n\ninput_layer = Input(shape=(input_dim, ))\n\n# encoder = Dense(40, activation=\"tanh\", \n#                 activity_regularizer=regularizers.l1(1e-10))(input_layer)\n# encoder = Dense(35, activation=\"tanh\")(encoder)\n# encoder = Dense(30, activation=\"tanh\")(encoder)\n# encoder = Dense(20, activation=\"tanh\")(encoder)\n# decoder = Dense(30, activation=\"relu\")(encoder)\n# decoder = Dense(35, activation=\"relu\")(decoder)\n# decoder = Dense(40, activation=\"relu\")(decoder)\n# decoder = Dense(input_dim, activation='relu')(decoder)\n\nencoder = Dense(40, activation=\"tanh\", \n                activity_regularizer=regularizers.l1(1e-5))(input_layer)\nencoder = Dense(20, activation=\"tanh\")(encoder)\ndecoder = Dense(20, activation=\"relu\")(encoder)\ndecoder = Dense(40, activation=\"relu\")(decoder)\ndecoder = Dense(input_dim, activation='relu')(decoder)\n\nautoencoder = Model(inputs=input_layer, outputs=decoder)\n\nautoencoder.compile(optimizer='adam', \n                    loss='mae', \n                    metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath=\"model_autoenc.h5\",\n                               verbose=0,\n                               save_best_only=True)\ntensorboard = TensorBoard(log_dir='./logs',\n                          histogram_freq=0,\n                          write_graph=True,\n                          write_images=True)\n\nhistory = autoencoder.fit(X_train, X_train,\n                    epochs=100,\n                    batch_size=32,\n                    validation_data=(X_val, X_val),\n                    verbose=1,\n                    callbacks=[checkpointer, tensorboard]).history\n\nwith open('model_autoenc_hist.txt', 'w') as outfile:  \n    json.dump(history, outfile)"
        }, 
        {
            "source": "### Evaluating the autoencoder results", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### We judge that the autoencoder converges well from both the loss and accuracy learning curves.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "with open('model_autoenc_hist.txt') as json_file:  \n    history_ld = json.load(json_file)\n    \nautoencoder_ld = load_model('model_autoenc.h5')\n\nplt.plot(history_ld['val_loss'])\nplt.plot(history_ld['loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Validation set','Training set'],loc='best');\nplt.show()\n\nplt.plot(history_ld['val_acc'])\nplt.plot(history_ld['acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Validation set','Training set'],loc='lower right');\nplt.show()"
        }, 
        {
            "source": "#### Since this dataset is imbalanced, we first investigate the confustion matrix for a fixed threshold. It turns out that while the autoencoder prediction is capable of rooting out a large portion of fraudulent transactions (high recall), it is at the same time relatively inaccurate in recognizing legal transactions (low precision).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True class')\n    plt.xlabel('Predicted class')\n    plt.grid(False)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "predictions = autoencoder_ld.predict(X_test) # Autoencoder predictions are feature values, not class labels.\nmse = np.mean(np.power(X_test - predictions, 2), axis=1) # Compute reconstruction error based on mean squared-error.\nerror_df = pd.DataFrame({'reconstruction_error': mse,\n                        'true_class': y_test})\n\nthreshold=1e-2 # Normalized to 1, this threshold is defined for MSE.\n\nLABELS=['Legal','Fraudulent']\nmaxval=np.max(error_df.reconstruction_error.values)\ny_pred = [1 if e > threshold*maxval else 0 for e in error_df.reconstruction_error.values] # Classify based on reconstruction error.\ncm = confusion_matrix(error_df.true_class, y_pred).astype('float64')\n\naccuracy=(cm[0][0]+cm[1][1])/cm.sum()\nprecision=(cm[1][1])/(cm[1][1]+cm[0][1])\nrecall=(cm[1][1])/(cm[1][1]+cm[1][0])\nprint(precision, recall)\nF1=2*precision*recall/(precision+recall)\nprint(\"Statistics for test data: accuracy,precision,recall,F1 \",accuracy,precision,recall,F1)\n\ncm = cm.astype('int')\nplt.figure(figsize=(6, 6))\nplot_confusion_matrix(cm, classes=LABELS,normalize= False,  title='Confusion matrix for test data')"
        }, 
        {
            "source": "#### More appropriately for such a highly imbalanced data, we should look at the precision-recall curve (https://doi.org/10.1371/journal.pone.0118432) and make sure that the area under it is large. This generally corresponds to high precision and high recall.  For our autoencoder, the area under the curve is indeed small.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)\nplt.plot(recall, precision)\nplt.title('Precision-Recall curve for test data')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.show()\n\nprint(\"Area Under PR Curve:\", auc(recall,precision))"
        }, 
        {
            "source": "#### We therefore need a better machine-learning algorithm to increase this area.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### (2) Let us train the computer with Support Vector Machines using Sklearn ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X_train, X_test = train_test_split(df_prep, test_size=0.3)  # Split data to 70% training and 30% test\n\ny_train = X_train['Class']\nX_train = X_train.drop('Class', axis=1)\ny_test = X_test['Class']\nX_test = X_test.drop('Class', axis=1)\n\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values\n\nclf = svm.SVC(kernel='rbf',verbose=True,max_iter=200,probability=True)\nclf.fit(X_train, y_train) \nyhat = clf.predict(X_test)"
        }, 
        {
            "source": "#### The confusion matrix reads", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cm = confusion_matrix(y_test, yhat).astype('float64')\n\naccuracy=(cm[0][0]+cm[1][1])/cm.sum()\nprecision=(cm[1][1])/(cm[1][1]+cm[0][1])\nrecall=(cm[1][1])/(cm[1][1]+cm[1][0])\nF1=2*precision*recall/(precision+recall)\nprint(\"Statistics for test data: accuracy,precision,recall,F1 \",accuracy,precision,recall,F1)\n\ncm = cm.astype('int')\nplt.figure(figsize=(6, 6))\nplot_confusion_matrix(cm, classes=LABELS,normalize= False,  title='Confusion matrix for test data') # Fixed at standard probability threshold of 0.5"
        }, 
        {
            "source": "#### We see that this time, compared to autoencoders, SVM gives a much more optimistic prediction with relatively high precision and recall. Its precision-recall curve also possesses a larger area.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "yhat_prob = clf.predict_proba(X_test)\nprecision, recall, th = precision_recall_curve(y_test, yhat_prob[:,1])\nplt.plot(recall, precision)\nplt.title('Precision-Recall curve for test data')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.show()\n\nprint(\"Area Under PR Curve:\", auc(recall,precision))"
        }, 
        {
            "source": "#### We shall see that it is indeed possible to improve this result further!", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### (3) We now train the machine with Decision Trees using Apache Spark", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "splits=df_credit.randomSplit([0.7,0.3]) # Split data to 70% training and 30% test\ndf_train=splits[0]\ndf_test=splits[1]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_train=reduce(DataFrame.drop, ['Time'], df_train)   # Drop 'Time' column from the training dataset\ndf_test=reduce(DataFrame.drop, ['Time'], df_test)     # Drop 'Time' column from the test dataset\n\nprint(len(df_train.columns),len(df_test.columns))\n\nheader = list(df_prep)\n\nvectorAssembler=VectorAssembler(inputCols=header,outputCol='features')                        # Assembler feature vector\nlabelIndexer = StringIndexer(inputCol=\"Class\", outputCol=\"indexedClass\").fit(df_train)        # Index class labels\n\nnormalizer = Normalizer(inputCol='features',outputCol='features_norm',p=2.0)                  # Normalize the feature matrix\n\ntree_classifier =RandomForestClassifier(labelCol='indexedClass',featuresCol='features_norm',numTrees=3,seed=0)    # Define a classifier\n\npipeline=Pipeline(stages=[vectorAssembler,labelIndexer,normalizer,tree_classifier])           # Assemble the ML pipeline"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model =pipeline.fit(df_train)\npredict_train=model.transform(df_train)\npredict_test=model.transform(df_test)"
        }, 
        {
            "source": "### Evaluate the Random-Forest predictions first with the confusion matrix", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### We find that RF only roots out most fraudulent cases, but also recognizes almost all legal transactions from the test dataset.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "results = predict_test.select(['prediction', 'Class'])\npredictionAndLabels=results.rdd\nmetrics = MulticlassMetrics(predictionAndLabels)\n\ncm=metrics.confusionMatrix().toArray()\naccuracy=(cm[0][0]+cm[1][1])/cm.sum()\nprecision=(cm[1][1])/(cm[1][1]+cm[0][1])\nrecall=(cm[1][1])/(cm[1][1]+cm[1][0])\nF1=2.*precision*recall/(precision+recall)\nprint(\"Statistics for test data: accuracy,precision,recall,F1 \",accuracy,precision,recall,F1)\n\ncm=cm.astype('int')\nplt.figure(figsize=(6, 6))\nplot_confusion_matrix(cm, classes=LABELS,normalize= False,  title='Confusion matrix for test data') # Fixed at standard probability threshold of 0.5"
        }, 
        {
            "source": "#### As a matter of fact, we obtain a rather large area for the precision-recall curve.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_proba=predict_test.select(\"probability\").collect()\ny_proba=np.asarray([x[0] for x in y_proba])\ny_test=predict_test.select(\"Class\").collect()\ny_test=np.asarray([x[0] for x in y_test])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "precision, recall, th = precision_recall_curve(y_test, y_proba[:,1])\nplt.plot(recall, precision)\nplt.title('Precision-Recall curve for test data')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0,1.03])\nplt.show()\n\neval = BinaryClassificationEvaluator().setMetricName('areaUnderPR').setLabelCol('Class').setRawPredictionCol(\"rawPrediction\")\nprint('Area under PR curve:',eval.evaluate(predict_test))"
        }, 
        {
            "source": "#### We therefore conclude that Decision Trees are the best alternative for detecting anomalous credit-card frauduluent activities. In effect, we have reproduced the general reported observation in the proceedings paper http://www.iaeng.org/publication/IMECS2011/IMECS2011_pp442-447.pdf ---- Decision-Tree classifiers outperform SVMs in credit-card fraud detection.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Conclusion", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "We have tested autoencoder neural networks, SVMs and decision-tree classifiers to train the computer for credit-card fraud detection. We find that autoencoder neural networks quite often misclassifies legal transactions as fraudulent on test/validation data even though they manage to root out a large portion of fraudulent transactions. SVMs improves this result by raising the precision, but it turns out that decision-tree algorithms are most reliable in recognizing legal and fraudulent transactions under highly imbalanced situations.", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}